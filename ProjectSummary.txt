Overview

Function approximation and integration are two fundamental problems in computational mathematics.  Function approximation using kernel methods arises in the construction of surrogates for computationally expensive simulations for climate modeling, drug design, and design of nuclear reactors.  Such kernel methods are also used for solving partial differential equations and for support vector machine classification.  Multivariate integration arises in the computation of option prices and value at risk in financial risk management.

We propose to contstruct algorithms for function approximation and integration that are computationally stable--avoiding catastrophic round-off error.  These algorithms will also be adaptive--determining the algorithm parameters based on function data to meet the user-specified error tolerance with rigorous justification.  Finally, these algorithms will be asymptotically efficient--requiring essentially the same computational effort as the best possible algorithms.

Intellectual Merit

Kernel methods also known as radial basis function methods or kriging methods are used for solving a variety of function approximation problems.  They involve inverting the Gram matrix, whose entries are the kernel function evaluated at pairs of data sites.  Unfortunately, Gram matrix is often numerically singular.  Recent work by the PIs has demonstrated that decomposing the kernel into its Hilbert-Schmidt SVD circumvents the numerical instability.  We intend to extend this method to a larger class of kernels and to customizing kernels and data sites based on function data.

The PIs have also developed adaptive multivariate integration algorithms with rigorous guarantees. The guarantees apply to cones of integrands. This research will extend these ideas to more general adaptive integration algorithms that handle relative error tolerances as well as absolute error tolerances.  We will also develop adaptive kernel methods for function approximation that are guaranteed for properly chosen cones of input functions.  Trustworthy adaptive algorithms will relieve the user of having to decide how many data sites are needed, or which kernel parameters are best. 

Broader Impact

The PIs will continue their long history of mentoring students at the high school through PhD level as well as post-doctoral scholars in research.  We will continue to reach out to underrepresented minorities and females.  Our mentoring is carried out through our ongoing research seminar, our research experiences for undergraduates (REUs), regular individual meetings, our support of students presenting their work at conferences, our hosting long-term visitors, and students completing their MS and PhD theses under our supervision. These activities will continue in this project.

The PIs will continue to disseminate their work through (invited) conference presentations, general interest talks to high school students, conference organizing, scholarly articles, a scholarly monograph, and publicly available software that implements our algorithms.  This research will make its way into the graduate courses that we teach, which will benefit tens of students each year.  As the greater community becomes aware of our results we expect them to infiltrate other graduate courses as well.  


