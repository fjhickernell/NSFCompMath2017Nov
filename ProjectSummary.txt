Overview

Function approximation and integration are two fundamental problems in computational mathematics. Function approximation using kernel methods arises in the construction of surrogates for computationally expensive simulations for climate modeling, drug design, and design of nuclear reactors. Such kernel methods are also used for solving partial differential equations and for support vector machine classification. Multivariate integration arises in the computation of option prices and value at risk in financial risk management.

We propose to construct algorithms for function approximation and integration that are computationally stable--avoiding catastrophic round-off error. These algorithms will also be adaptive--determining the algorithm parameters based on function data to meet the user-specified error tolerance with rigorous justification. Finally, these algorithms will be asymptotically efficient--requiring essentially the same computational effort as the best possible algorithms.

Intellectual Merit

Kernel methods, also known as radial basis function methods or kriging methods, are used for solving a variety of function approximation problems. They involve inverting the Gram matrix, whose entries are the kernel function evaluated at pairs of data sites. Unfortunately, the Gram matrix is often numerically singular. Recent work by the PIs has demonstrated that decomposing the Gram matrix into its Hilbert-Schmidt SVD can circumvent this numerical instability. We will extend this method to a larger class of kernels and to customizing kernels and data sites based on the available function data (such as the output from expensive computer simulations).

The PIs have also developed adaptive multivariate integration algorithms with rigorous guarantees. The guarantees apply to cones of integrands. This research will extend these ideas to more general adaptive integration algorithms that handle relative error tolerances as well as absolute error tolerances, that employ control variates, and that use multi-level ideas to handle the limit of infinite dimension. We will also develop adaptive kernel methods for function approximation that are guaranteed for properly chosen cones of input functions. Trustworthy adaptive algorithms will relieve the user of having to decide how many data sites are needed, or which kernel parameters are best. 

Broader Impact

The PIs will continue their longstanding practice of mentoring students at the high school through PhD level as well as post-doctoral scholars. We will continue to reach out to underrepresented minorities and females. Our mentoring is carried out through our ongoing research seminar, our research experiences for undergraduates (REUs), regular individual meetings, our support of students presenting their work at conferences, our hosting long-term visitors, and students completing their MS and PhD theses under our supervision. These activities will all continue in this project and will result in a better prepared and more diverse STEM workforce.

The PIs will continue to disseminate their work through (invited) conference presentations, general interest talks to high school students, conference organizing, scholarly articles, a scholarly monograph, and publicly available software that implements our algorithms. This research will make its way into the courses that we teach, which will benefit tens of students each year. As the greater community becomes aware of our results we expect them to infiltrate other graduate and undergraduate courses as well. 

Benefits to the broader society will be provided by an ongoing collaboration in which kernel methods are applied to the detection of brain activity from MEG and EEG data, and a new project in which we will employ kernels in predicting the spread of Ebola. The former application potentially will help in the early detection of neurophysiological diseases, and the aim of the latter is to better manage the Ebola epidemic in West Africa.
