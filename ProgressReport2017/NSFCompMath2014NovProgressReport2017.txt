%% Accomplishments
% Major Goals

This research is comprised of four projects related to function approximation and integration:

1. Extending our research on the Hilbert-Schmidt SVD by identifying more kernels and their Mercer series for which the Hilbert-SVD can be implemented,

2. Extending our research on guaranteed, adaptive algorithms, 

3. Obtaining guaranteed, adaptive algorithms for kernel methods, and 

4. Applying our new results to various problems.

% Major Activities

Project 1. 
a) Fasshauer collaborated with Jalil Rashidinia and Manoochehr Khasi on an alternative approach to implementing Hilbert-Schmidt eigenfunctions of the Gaussian kernel by using Chebyshev polynomials instead of Hermite polynomials in the expansion used in our earlier work. This enhances the numerical stability of the algorithm. This new eigenfunction representation was also applied to the numerical solution of nonlinear unsteady convection-diffusion-reaction equations.

b) Fasshauer has been collaborating with Paul Martin to extend an earlier derivation for eigenfunctions and eigenvalues of the $C^0$ Matern kernel on the half line from the monograph Fasshauer and McCourt (2015) to the entire real line. Extensions to smoother Matern kernels are currently being investigated. 

Project 2. 
a) Hickernell and and Lluis Antoni Jiménez Rugama improved the earlier work by Hickernell and Jiang on relative and hybrid error tolerances.  We found a better way to determine the best estimate of the integral.  This is not necessarily the sample mean.  “Better” means an estimate that satisfies a tighter error tolerance for both adaptive IID Monte Carlo and adaptive quasi-Monte Carlo algorithms.

b) Hickernell, Jiménez Rugama, and Da Li completed and published their work implementing control variates for quasi-Monte Carlo.

c) Hickernell and Jiménez Rugama also extended the work on hybrid error bounds to methods for estimating a function of several integrals within a given error tolerance.  Such problems arise in Bayesian inference and Sobol’ indices.

d) Hickernell, Sou-Cheng Choi, Yuhan Ding and Xin Tong published their work on locally adaptive function approximation and optimization and implemented it in the Guaranteed Automatic Integration Library (GAIL) MATLAB toolbox.

e) Undergraduate students Yueyi Li and Cu Hauw Hung explored internal control variates based on several variable transformations that lead to the same integral.  Their automatic cubature algorithms choose the optimal combination of these internal control variates.

Project 3.
a) Hickernell and Jagadeeswaran Rathinavel investigated the effectiveness of Bayesian cubature for adaptively integrating multivariate functions.  We also discovered a deterministic (non-Bayesian) context, which mimics kernel methods for integration.  This includes a non-Bayesian interpretation of maximum likelihood estimation.  By focusing on kernels of a special form related to the low discrepancy point set, we are able to perform the required matrix inversion and eigenvalue decomposition in O(n \log n) operations rather than O(n^3) operations.  In some cases this requires periodizing variable transformations.

Project 4.
a) Fasshauer extended his collaboration with P.K. Mishra, S.K. Nath and M.K. Sen to the numerical solution of partial differential equations with a kernel-based finite difference method based on the hybrid radial kernel composed of a Gaussian part along with a cubic part studied in a previous paper. In particular, a geophysics application to the solution of a frequency-domain wave equation was investigated.

b) In the collaboration with J. Rashidinia and M. Khasi mentioned earlier, Fasshauer applied the Hilbert-Schmidt SVD for Gaussian kernels in a new Chebyshev polynomial-based representation to the numerical solution of nonlinear unsteady convection-diffusion-reaction equations.

c) Fasshauer collaborated with Mike McCourt on an application of product iterated Brownian bridge kernels formed with the Hilbert-Schmidt SVD to a black box Bayesian optimization algorithm following the sequential kriging approach.

d) Fasshauer is collaborating with Brad Martin, Atef Elsherbeni and Mohammed Hadi on the application of interface-aware kernel-based finite difference methods to the numerical solution of 2D Maxwell equations as they apply to problems in antenna design.

e) Fasshauer is supervising an REU project with Paul Wolfert on the use of kernel-based numerical methods for space-time collocation.

f) Together with Alessandra De Rossi, Roberto Cavoretto and Emma Perracchione, Fasshauer is developing an anisotropic partition of unity method for the numerical solution of partial differential equations.

g) Undergraduate Tianci Zhu and MS student Xiaoyang Zhao implemented the QE approximation to the Heston model for stock price paths.  They discovered a modification to the QE algorithm that was necessary to preserve the desired convergence rate for vanishing volatility of the variance.  This has been implemented in the GAIL toolbox.

h) Jiménez Rugama continued collaborating with scientists at Fermilab to use our adaptive quasi-Monte Carlo algorithms for computations in high energy physics.

i) Jiménez Rugama and Hickernell completed a collaboration with Clémentine Prieur and her group on efficient computation of Sobol' indices, used in uncertainty quantification. Two publications resulted.

j) Kan Zhang has explored using adaptive quasi-Monte Carlo algorithms for Bayesian inference, the choice of the sampling distribution (variable transformation) to make the problem amenable to such algorithms is under investigation.

% Specific Objectives
Project 1. 
a) We want to enhance the numerical stability and computational efficiency of the Hilbert-Schmidt SVD for Gaussian kernels. The idea is to use a "better" basis for the polynomial part of the eigenfunctions and exploit special properties of eigenfunctions, such as their orthogonality and location of their zeros. The use of Chebyshev polynomials instead of Hermite polynomials has provided some success. 

b) Using various techniques from the classical theory of integral equations and known facts about special functions (such as Bessel functions), we want to make progress on the analytical derivation of eigenfunction expansions for kernels widely used in practice such as the family of Matern kernels, which is popular both in the statistics and numerical analysis communities.

Project 2.
a) Important practical problems, such as Bayesian inference and Sobol' indices, require an answer that is a function of several integrals, not only a single integral.  We attempted to develop our earlier adaptive algorithms to accommodate such situations.  This is a non-trivial exercise since plugging in the sample averages for the corresponding integrals may lead to poor estimates.

b) In our attempt to increase the efficiency of our adaptive cubature algorithms and to prevent the need for user-tuning, we wanted to add control variates and internal control variates to our algorithms.  The internal control variates arise from different transformations of the integration variable.  This frees the user from having to determine which variable transformation is the optimal one.  Several transformations can be used simultaneously with the better one winning out.

c) The GAIL toolbox showcases our algorithms and makes them available for others to use.  They are used extensively in the Monte Carlo class taught by Hickernell each fall.  We want to provide more advanced options to the users of our GAIL toolbox.

Project 3.
a) As an alternative to our other adaptive low discrepancy methods, we wanted to explore Bayesian cubature, which has been given increased attention by the probabilistic numerics community.  We also wanted to ensure that these calculations did not require burdensome calculations, which is why we explored using kernels of a special form.  The lessons learned here we hoped will inform the function approximation problem.

Project 4.
a) The monograph by Fasshauer and McCourt (2015) has served as the foundation for looking at kernel-based methods from both a deterministic and stochastic perspective, and then apply insights gained in one domain to the other. A recent collaboration by the two of us has applied this strategy to black-box optimization.

b) Since radial basis function methods can be interpreted as generalizations of polynomial methods we are investigating the use of kernel-based finite difference methods and the flexibility gained by added generality in various application areas such as in geophysics and electromagnetics. 

c) We want to facilitate option pricing to a user-defined error tolerance via (quasi-) Monte Carlo with the more realistic stochastic volatility model.  In the course of their work, Zhao and Zhu found that existing code gives poor accuracy for small volatility of the variance of the asset price.  They needed to modify the algorithm to correct this error.

d) The objective of the collaboration between Jiménez Rugama and Fermilab was to apply more advanced techniques to speed up computation of the integrals required to infer from the observed data the most likely particle interactions that are occurring.

e) We wanted to demonstrate the efficacy of our automatic quasi-Monte Carlo cubature algorithms on the problem of Sobol' indices.  Since these are defined as a function of more than one integral satisfying the error tolerance is more complicated.

f) Bayesian inference is a very important application area, but quasi-Monte Carlo methods are not used much because integrands are peaky.  We wanted to investigate whether our adaptive methods could be used to efficiently compute the answer to simple Bayesian inference problems.


%% Significant Results
Project 1. 
a) A paper has been submitted that details the new Chebyshev polynomial-based eigenfunction representation of the Gaussian kernel and uses this representation to solve nonlinear unsteady convection-diffusion-reaction equations.

b) So far, we have been able to extend earlier results for low-order Matern kernels from the half-line to the entire real line. We are looking for ways to "lift" the techniques to accomplish this to the case of higher-order Matern kernels before preparing a paper on the topic.

Project 2. 
a) A successful, and provably optimal, method for satisfying error criteria of the form 

|true(>=1 integrals) - approx| \le max(\epsilon_abs, \epsilon_rel x |true(>=1 integrals)| 

has been derived.  Here true(>=1 integrals) is the true answer, a function of several integrals, and approx is some function of the sample means of the integrands at well chosen points and the data-based error bounds for the individual integrals. This work has been submitted and the positively reviewed manuscript has been revised and is under consideration.

b) New locally adaptive algorithms for univariate function approximation and optimization have been found with computational cost that proportional to \sqrt{||f''||_{1/2}/\epsilon}, where \epsilon is the desired error tolerance.  These costs can be significantly smaller than the \sqrt{||f''||_{\infty}/\epsilon} costs of globally adaptive algorithms, because the 1/2-quasi-norm of a somewhat spiky function may be much smaller than the sup-norm of that same function.  A paper has been published.

c) By computing the discrete Fourier Walsh coefficients, it is possible to compute the optimal control variate coefficient as the function is being sampled, and in a way consistent with earlier observations by Hickernell, Lemieux, and Owen (2005).  This work is under review.

d) We are able to adaptively determine the sample size for Bayesian cubature assuming that the integrand is a Gaussian process and that the covariance kernel is accurately determined by maximum likelihood estimation.  We also discovered a previously unknown deterministic interpretation of Bayesian cubature.  Some of these results are in a tutorial paper that has received a positive review and is under revision.

Project 4.
a) A joint paper has been submitted to a geophysics journal presenting the kernel-based finite difference method for the numerical solution of partial differential equations with the hybrid Gaussian-cubic kernel studied earlier.

b) A joint paper has been submitted that discusses the numerical solution of nonlinear unsteady convection-diffusion-reaction equations with the new Chebyshev polynomial-based representation of the Gaussian eigenfunctions within the Hilbert-Schmidt SVD algorithm.

c) Fasshauer and McCourt each gave presentations black box Bayesian optimization algorithm using the iterated Brownian bridge product kernels.

d) A joint paper for an electrical engineering journal is in preparation that compares the use of interface-aware kernel-based finite difference methods to standard finite difference methods for the 2D Maxwell equations as they apply to problems in antenna design.

e) By altering the approximation to the integral of the variance, they avoided amplified errors for small volatility of the variance.  The modified algorithm provides more accurate answers.  This work formed part of Xiaoyang Zhao's MS thesis completed in the spring of 2017.

f) In the course of his work with Fermilab, Jiménez Rugama discovered the the MATLAB's own versions of the Sobol' sequence had been incorrectly coded.  This error and the suggested fix were brought to the attention of the Mathworks.  They were fixed in MATLAB's 2017a released.

g) Automatic integration has been successfully applied to a Bayesian inference problem for logistic regression.

% Key Outcomes and Achievements

Project 1.
To our knowledge, it is the first time that eigenfunctions and eigenvalues on the real line for a kernel in the Matern family have been derived analytically. Thus far, such results were available only on bounded intervals.   

Project 2. 
a) We have found a way to construct adaptive algorithms for more general problems—functions of several integrals—and more general error criteria involving absolute and relative error criteria.  This paradigm can be used for different kinds of problems beyond integration.

b) Adaptive Bayesian cubature based on low discrepancy sequences and kernels of special form have been found to be fast and accurate in practice as well as theory.

Project 4.
Kernel-based function approximation and adaptive cubature have been used to solve a wide variety of scientific and engineering problems.



%% Training and professional development
During the last year there have been several students involved in this project:

Yuhan Ding, a visiting assistant professor at Illinois Tech co-authored a paper during this grant period and obtained a tenure track position for the fall of 2017.

Lluís Antoni Jiménez Rugama, supported as an RA by this grant, co-authored two publications during this grant period and finished his PhD in December 2016.  He presented talks at the August 2016 12th International Conference on Monte Carlo and Quasi-Monte Carlo Methods in Scientific Computing and prepared a talk (presented by Hickernell) at the July 2017 11th International Conference on Monte Carlo Methods and Applications.

Jagadeeswaran Rathinavel has been working on his PhD research dealing with Bayesian cubature.

Kan Zhang, supported by this grant, is working on his PhD research on quasi-Monte Carlo methods for Bayesian inference.  He gave a talk at the July 2017 11th International Conference on Monte Carlo Methods and Applications.

Yizhi Zhang is (slowly) working on his PhD research.

Da Li gave a talk at the August 2016 Joint Statistics Meetings.

Xiaoyang Zhao completed her MS thesis in May 2017.  She gave a talk at the 2016 Joint Statistics Meetings.  She is writing up for publication the work that she and Zhu did on the Heston model.

Jiazhen Lu is working on her MS research.

Tanner Johnson, an undergraduate student from U Minnesota and supported during summer 2016 by this grant, worked on the characterization of reproducing kernel Hilbert spaces via the Hilbert-Schmidt decompositions of their kernels. A manuscript for a joint paper is in preparation.  He will be entering a PhD program at the University of British Columbia in the fall of 2017.

Paul Wolfert, an undergraduate student at the Colorado School of Mines supported during summer 2017 by this grant, is investigating the use of kernel-based collocation methods to jointly solve space-time partial differential equations. 

Tianci Zhu, received her BS from Illinois Tech in May 2017 and will enter NYU's MS in Mathematics in Finance.  She is writing up for publication the work that she and Zhao did on the Heston model.


%% Dissemination of results

Our work has been presented at several meetings:

Talk by Hickernell at the Joint Statistics Meetings, at Chicago, August 2016.

Invited tutorial by Hickernell at the 12th International Conference on Monte Carlo and Quasi-Monte Carlo Methods in Scientific Computing, at Stanford, CA, August 2016.

Talk by Fasshauer at Multivariate Approximation and Interpolation with Applications (MAIA 2016) in Luminy, France, September 2016.

Talk by Hickernell at Information-Based Complexity 2016, in Bedlewo, Poland, September, 2016.

Talk by Hickernell at the Joint Mathematics Meetings, January 2017.

Talks by Fasshauer and Hickernell at the 2017 SIAM CSE Conference in Atlanta, February 2017.

Talk by Fasshauer at the International Conference on Kernel-Based Approximation Methods in Machine Learning in Guangzhou, China, May 2017. 

Talk by Hickernell at the 11th International Conference on Monte Carlo Methods and Applications, July 2017.

Colloquium talks by Hickernell at Georgia Tech, Tulane, Colorado School of Mines.

Several manuscripts have been submitted for publication and published.  These are detailed in the products section of the report.  In addition, we have continued to grow the GAIL toolbox, which contains algorithms backed by the theory developed in our articles.


%% What are we planning to do

Some of the work mentioned above needs to be written up and submitted for publication.  As we do that, we will clarify our results.

We want to extend the Bayesian cubature success to function approximation.  We want to explore smooth, scramble invariant kernels with Sobol' sequences.

We want to extend our low convergence order guaranteed algorithms for univariate problems to higher order.  This involves moving from linear splines to higher order piecewise polynomial approximations or high degree polynomial approximations using Chebyshev nodes.

We want to further explore and exploit the interplay between the deterministic and stochastic perspective of various algorithms. 

Some of our friends are engaged with high dimensional problems where function approximation is expensive.  They have had some success with low degree polynomials.  We want to understand whether kernel methods are competitive and also what kind of high dimensional problems can be solved with a low number of function values.

%%% Impact
%% Impact on the principle disciplines
This project has developed adaptive algorithms for univariate and multivariate integration, for univariate function approximation, and for univariate optimization.  Unlike other popular algorithms where the adaptivity is based on heuristics, our algorithms are theoretically justified.  A paradigm has been established for rigorously analyzing the error of adaptive algorithms, and the important details are being worked out for various cases.  The computational costs of these new adaptive algorithms depend in some surprising ways on the quasi-norm of the function being integrated, approximated, or optimized.  In addition, insights from both (deterministic) numerical analysis and statistics have allowed us to develop stable and efficient kernel- based methods for integration, interpolation, optimization, and the collocation solution of PDEs.


%% Impact on other disciplines
The basic operations of integration, function approximation, and optimization are used in a number of application areas in finance, engineering and science.  We are providing more efficient, robust and convenient tools, which will expedite the discovery of new science.

%% Impact on the development of human resources
Our mentees at many stages of their careers have learned how to 
o identify meaningful problems, 
o determine where the challenging parts are, 
o understand the existing state of the art, 
o identify new methods for attacking the problem,
o assess their success, 
o work as a team to solve problems, and
o report their work to their peers, orally and in written form.

%% Impact on physical resources

%% Impact on institutional resources
The activity in this project has been a part of the impetus for the institution to start a Center for Interdisciplinary Scientific Computation in May 2017 with Hickernell as the first director.

%% Impact on information resources

%% Impact on technology transfer

%% Impact on society beyond science and technology